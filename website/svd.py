# -*- coding: utf-8 -*-
"""tseting_ml_python_recommender2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SsIjC3mqZkJZcKrPSzD4hZyhmTEMWaSH
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from scipy.sparse import csr_matrix
from sklearn.neighbors import NearestNeighbors
import matplotlib.pyplot as plt
# %matplotlib inline


movies = pd.read_csv('Data/movies.csv')

movies.sample(10)

ratings = pd.read_csv('Data/ratings.csv')

ratings.head()

combine_movie_rating= pd.merge(ratings,movies,on='movieId')
combine_movie_rating=combine_movie_rating.drop(['timestamp'],axis = 1)
print(len(combine_movie_rating))
combine_movie_rating.head()

combine_movie_rating = combine_movie_rating.dropna(axis = 0 ,subset=['title'])
print(len(combine_movie_rating))
combine_movie_rating.head()

movie_rating_count=pd.DataFrame(combine_movie_rating.
                    groupby(['movieId'])['rating'].
                    count().
                    reset_index().
                    rename(columns={'rating':'totalRatingCount'})
                   )
movie_rating_count.head()

pd.set_option('display.float_format', lambda x: '%.3f' % x)
print(movie_rating_count['totalRatingCount'].describe())

print(movie_rating_count['totalRatingCount'].quantile(np.arange(.9,1,.01)))

rating_with_totalRatingCount = combine_movie_rating.merge(movie_rating_count,left_on='movieId',right_on='movieId')
print(len(combine_movie_rating))
print(len(rating_with_totalRatingCount))
rating_with_totalRatingCount.head()

#10% of the movies have more than 158 reviews
popular_threshold=158
rating_popular_movies= rating_with_totalRatingCount.query('totalRatingCount>=@popular_threshold')
rating_popular_movies.head()

ratings_pivot2 = rating_popular_movies.pivot(index='userId', columns='movieId',values='rating').fillna(0)
ratings_pivot2_sparse = csr_matrix(ratings_pivot2.values)
print(ratings_pivot2.shape)
ratings_pivot2.head()

X=ratings_pivot2.values.T
X.shape

from sklearn.decomposition import TruncatedSVD
svd=TruncatedSVD(n_components=10,random_state=17)
matrix=svd.fit_transform(X)


import warnings
warnings.filterwarnings("ignore",category=RuntimeWarning)
corr=np.corrcoef(matrix)

corr
with open("../svd.csv", 'ab') as f:
    for x in range(1, movies.shape[0]):
        try:
            if (movies['movieId'] == x).any():
                example_movieId = x
                currentmovie = " "
                movielist = []
                movieIds = ratings_pivot2.columns
                movieIds_list = list(movieIds)
                movieId_index = movieIds_list.index(example_movieId)

                movieId_vec = corr[movieId_index]
                argsort_idx = np.argsort(-movieId_vec)[:11]
                coff = movieId_vec[argsort_idx]
                similar_movie_Ids = movieIds[argsort_idx]

                similar_movie_Ids

                for idx, mId in enumerate(similar_movie_Ids):
                    name = movies[movies.movieId == mId]['title'].values[0]
                    if idx == 0:
                        currentmovie = name
                    else:
                        movielist.append(name)
                result = pd.DataFrame([[example_movieId, currentmovie, movielist]])
                result.to_csv(f, header=False, index=False)

        except ValueError:
            pass
